{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3e80ce",
   "metadata": {},
   "source": [
    "# Primer scrapeo\n",
    "\n",
    "El proceso de scrapear una página web es parecido a lo que hace un humano cuando quiere buscar algo en Internet, la diferencia es que en lugar de ver el contenido presentado por el navegador, el programa analiza y selecciona el código fuente generalmente programado en  HTML y JavaScript.\n",
    "\n",
    "El primer paso es por tanto seleccionar una página web para hacer el scraping y descargarla. Ya sabemos cómo hacer peticiones HTTP mediante `requests` así que vamos a a hacer una petición de la web de ejemplo por excelencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26822a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "req = requests.get(\"https://example.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552458ca",
   "metadata": {},
   "source": [
    "El caso es que como respuesta a la petición se nos ha develto la página y podemos ver su código fuente en crudo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ec71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(req.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51ea8c",
   "metadata": {},
   "source": [
    "Aquí tenemos un documento HTML bien estructurado con sus etiquetas.\n",
    "\n",
    "Cuando el navegador interpreta estas etiquetas que se abren y se cierran, con sus atributos y contenidos genera lo que se conoce como **DOM** (*Document Object Model*), una interfaz de programación para documentos HTML y XML que en esencia es como un árbol ramificado de  componentes padres e hijos. El padre de todo es `html`, que tiene dos hijos `head` y `body`, el primero contiene el `title` y los metadatos, el otro el contenido de la página, una capa `div` que a su vez tiene una cabecera `h1` y unos parágrados `p`.\n",
    "\n",
    "Pues bien, la biblioteca `BeautifulSoup` lo que hace es generar su propia estructura parecida a la interfaz **DOM** pero en Python, creando un árbol con los elementos del documento. Básicamente le pasamos un documento HTML en crudo y ella lo transforma en un objeto dinámico con el que podemos interactuar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(req.text)\n",
    "\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39e0c5",
   "metadata": {},
   "source": [
    "A simple vista parece lo mismo, pero ahora podemos hacer algo como esto para consultar el título de la página:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587527d",
   "metadata": {},
   "source": [
    "Esto que nos devuelve es un objeto, veamos tu tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe08602",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.select(\"title\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f3cc2",
   "metadata": {},
   "source": [
    "Es un conjunto de resultados que contiene los tags que concuerdan con el nombre `title`, por tanto es una lista.\n",
    "\n",
    "Veamos qué tipo tiene ese primer valor del conjunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.select(\"title\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1bce7",
   "metadata": {},
   "source": [
    "Como véis es un `Tag` y éste contiene diferentes métodos, como por ejemplo `getText()` para recuperar su contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c04bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"title\")[0].getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d5293",
   "metadata": {},
   "source": [
    "Podemos recuperar otros elementos esenciales como la cabecera o los parágrafos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7cda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"h1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b49dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ecf2e",
   "metadata": {},
   "source": [
    "Fijaros que el segundo parágrafo contiene a su vez un enlace, podemos acceder de forma anidada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar del segundo parágrafo el primer enlace \n",
    "a = soup.select(\"p\")[1].select(\"a\")[0]\n",
    "\n",
    "# Mostrar su contenido\n",
    "a.getText()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319dea5",
   "metadata": {},
   "source": [
    "Las etiquetas tienen valores especiales llamados atributos, como la dirección `href` de un enlace. \n",
    "\n",
    "Estos se almacenan como un diccionario del objeto, es muy cómodo acceder a ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c214838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributo con la dirección del enlace\n",
    "a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c248a",
   "metadata": {},
   "source": [
    "Estos valores están mapeados del diccionario `attrs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55291454",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.attrs.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef5b18b",
   "metadata": {},
   "source": [
    "Siguiendo esta lógica podemos programar un script que recupere todos los atributos de los metadatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796019cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta in soup.select(\"meta\"):\n",
    "    for atributo, valor in meta.attrs.items():\n",
    "        print(f\"{atributo}: {valor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a1c2b",
   "metadata": {},
   "source": [
    "Solo con esto os podéis hacer una ideal del potencial que tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157e9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
